{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# requirements: pdfplumber, pandas, tabula-py , numpy\n",
    "import re, pdfplumber, pandas as pd, numpy as np\n",
    "import mysql.connector \n",
    "from sqlalchemy import create_engine\n",
    "from pathlib import Path\n",
    "from mysql.connector import errorcode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDFS = [\n",
    "    \"pdfs/PA_OTO√ëO_2025_SEMESTRAL_ICC.pdf\",\n",
    "    \"pdfs/PA_OTO√ëO_2025_SEMESTRAL_ITI.pdf\",\n",
    "    \"pdfs/PA_OTO√ëO_2025_SEMESTRAL_LCC.pdf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_header(cols):\n",
    "    return [re.sub(r\"\\s+\", \" \", c).strip().lower() for c in cols]\n",
    "\n",
    "def extract_tables_pdfplumber(pdf_path):\n",
    "    rows = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            for table in page.extract_tables():\n",
    "                if not table or len(table) < 2: \n",
    "                    continue\n",
    "                header = clean_header(table[0])\n",
    "                # heur√≠stica: columnas esperadas\n",
    "                if {\"nrc\",\"clave\",\"materia\",\"d√≠as\",\"hora\",\"profesor\",\"sal√≥n\"}.issubset(set(header)) or \\\n",
    "                   {\"nrc\",\"clave\",\"materia\",\"dias\",\"hora\",\"profesor\",\"salon\"}.issubset(set(header)):\n",
    "                    for r in table[1:]:\n",
    "                        if r and any(x for x in r):\n",
    "                            rows.append(dict(zip(header, r)))\n",
    "    return pd.DataFrame(rows) if rows else pd.DataFrame()\n",
    "\n",
    "def extract_all():\n",
    "    frames = []\n",
    "    for p in PDFS:\n",
    "        if Path(p).exists():\n",
    "            df = extract_tables_pdfplumber(p)\n",
    "            if not df.empty:\n",
    "                df[\"origen_pdf\"] = Path(p).name\n",
    "                frames.append(df)\n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()\n",
    "\n",
    "raw = extract_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizaci√≥n de encabezados frecuentes\n",
    "raw = raw.rename(columns={\n",
    "    \"dias\": \"d√≠as\", \"salon\": \"sal√≥n\"\n",
    "})\n",
    "\n",
    "# Limpieza de profesor\n",
    "def normalizar_profesor(x: str):\n",
    "    if not isinstance(x, str):\n",
    "        return None\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "    x = x.replace(\" - \", \" \")\n",
    "    return x.title()\n",
    "\n",
    "raw[\"profesor\"] = raw[\"profesor\"].apply(normalizar_profesor)\n",
    "\n",
    "# Pasar todo a min√∫sculas y eliminar espacios\n",
    "raw.columns = [c.strip().lower() for c in raw.columns]\n",
    "\n",
    "# Asegurar que exista la columna 'hora'\n",
    "if \"horario\" in raw.columns and \"hora\" not in raw.columns:\n",
    "    raw.rename(columns={\"horario\": \"hora\"}, inplace=True)\n",
    "elif \"hora \" in raw.columns:\n",
    "    raw.rename(columns={\"hora \": \"hora\"}, inplace=True)\n",
    "elif \"hora\\n\" in raw.columns:\n",
    "    raw.rename(columns={\"hora\\n\": \"hora\"}, inplace=True)\n",
    "elif \"h\" in raw.columns:  # casos raros de extracci√≥n truncada\n",
    "    raw.rename(columns={\"h\": \"hora\"}, inplace=True)\n",
    "\n",
    "# Si sigue sin existir, crear una columna vac√≠a para evitar errores posteriores\n",
    "if \"hora\" not in raw.columns:\n",
    "    raw[\"hora\"] = None\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Funci√≥n para parsear horas de forma robusta\n",
    "# ---------------------------------------------------------\n",
    "def parse_hora(rango):\n",
    "    \"\"\"Parses hour ranges like '0700-0859', '07:00-08:59', '7:00 - 8:59'.\"\"\"\n",
    "    if not isinstance(rango, str):\n",
    "        return pd.Series([None, None, None])\n",
    "    \n",
    "    s = rango.strip()\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    if s.lower() in [\"nan\", \"none\", \"\"]:\n",
    "        return pd.Series([None, None, None])\n",
    "\n",
    "    patron = r\"(\\d{1,2}):?(\\d{2})-(\\d{1,2}):?(\\d{2})\"\n",
    "    m = re.match(patron, s)\n",
    "    if not m:\n",
    "        return pd.Series([None, None, None])\n",
    "\n",
    "    h1, m1, h2, m2 = map(int, m.groups())\n",
    "    start = pd.to_datetime(f\"{h1:02d}:{m1:02d}\", format=\"%H:%M\", errors=\"coerce\")\n",
    "    end   = pd.to_datetime(f\"{h2:02d}:{m2:02d}\", format=\"%H:%M\", errors=\"coerce\")\n",
    "\n",
    "    if pd.isna(start) or pd.isna(end):\n",
    "        return pd.Series([None, None, None])\n",
    "    duracion = int((end - start).total_seconds() / 60)\n",
    "    if duracion <= 0:\n",
    "        return pd.Series([None, None, None])\n",
    "\n",
    "    return pd.Series([start.time(), end.time(), duracion])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Aplicar la funci√≥n y crear las tres columnas\n",
    "# ---------------------------------------------------------\n",
    "raw[[\"h_inicio\", \"h_fin\", \"duracion_min\"]] = raw[\"hora\"].apply(parse_hora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIA_MAP = {\"L\":\"Lunes\",\"A\":\"Martes\",\"M\":\"Miercoles\",\n",
    "           \"J\":\"Jueves\",\"V\":\"Viernes\",\"S\":\"S√°bado\"}\n",
    "\n",
    "# Expandir por m√∫ltiples d√≠as en una sola fila (si aplica)\n",
    "def explotar_por_dia(df):\n",
    "    out = []\n",
    "    for _, row in df.iterrows():\n",
    "        dias = str(row[\"d√≠as\"]).replace(\" \", \"\")\n",
    "        if \",\" in dias:\n",
    "            tokens = dias.split(\",\")\n",
    "        else:\n",
    "            tokens = list(dias)  # \"AJL\" -> [\"A\",\"J\",\"L\"]\n",
    "        for d in tokens:\n",
    "            r = row.copy()\n",
    "            r[\"dia_codigo\"] = d\n",
    "            r[\"dia_semana\"] = DIA_MAP.get(d, d)\n",
    "            out.append(r)\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "curated = explotar_por_dia(raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas sin id_materia: 0\n"
     ]
    }
   ],
   "source": [
    "# Sal√≥n -> edificio/aula: \"1CCO4/203\" -> edificio=1CCO4, aula=203\n",
    "def split_salon(s):\n",
    "    if not isinstance(s, str): return pd.Series([None, None, None])\n",
    "    s = s.strip()\n",
    "    m = re.match(r\"([^/]+)/?(\\w+)?\", s)\n",
    "    if not m: return pd.Series([s, None, s])\n",
    "    edificio, aula = m.group(1), m.group(2)\n",
    "    return pd.Series([edificio, aula, s])\n",
    "\n",
    "curated[[\"edificio\",\"aula\",\"codigo_salon\"]] = curated[\"sal√≥n\"].apply(split_salon)\n",
    "\n",
    "# Dimensiones (surrogate keys)\n",
    "def build_dim(df, col_key, cols_keep, start_id=1, name_id=\"id\"):\n",
    "    d = df[cols_keep].drop_duplicates().reset_index(drop=True)\n",
    "    d.insert(0, name_id, range(start_id, start_id+len(d)))\n",
    "    return d\n",
    "\n",
    "dim_docente = build_dim(curated, \"profesor\", [\"profesor\"], name_id=\"id_docente\")\n",
    "dim_materia = build_dim(curated, \"materia\", [\"clave\",\"materia\"], name_id=\"id_materia\")\n",
    "dim_espacio = build_dim(curated, \"codigo_salon\", [\"edificio\",\"aula\",\"codigo_salon\"], name_id=\"id_espacio\")\n",
    "\n",
    "# dim_tiempo por fila (d√≠a + rango)\n",
    "dim_tiempo = curated[[\"dia_codigo\",\"dia_semana\",\"h_inicio\",\"h_fin\"]].drop_duplicates().reset_index(drop=True)\n",
    "dim_tiempo.insert(0, \"id_tiempo\", range(1, len(dim_tiempo)+1))\n",
    "\n",
    "# Hechos (join a dimensiones)\n",
    "def map_id(df, dim, key_cols_df, key_cols_dim, id_col):\n",
    "    if isinstance(key_cols_df, str):\n",
    "        key_cols_df = [key_cols_df]\n",
    "    if isinstance(key_cols_dim, str):\n",
    "        key_cols_dim = [key_cols_dim]\n",
    "\n",
    "    df[\"_key_\"] = df[key_cols_df].astype(str).agg(\"|\".join, axis=1)\n",
    "    dim[\"_key_\"] = dim[key_cols_dim].astype(str).agg(\"|\".join, axis=1)\n",
    "\n",
    "    merged = df.merge(dim[[\"_key_\", id_col]], on=\"_key_\", how=\"left\", validate=\"m:1\")\n",
    "    result = merged[id_col].values\n",
    "\n",
    "    df.drop(columns=\"_key_\", inplace=True, errors=\"ignore\")\n",
    "    dim.drop(columns=\"_key_\", inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return result\n",
    "\n",
    "hechos = curated.copy()\n",
    "hechos[\"id_docente\"] = map_id(hechos, dim_docente, \"profesor\", \"profesor\", \"id_docente\")\n",
    "hechos[\"id_materia\"] = map_id(hechos, dim_materia, [\"clave\",\"materia\"], [\"clave\",\"nombreMateria\" if \"nombreMateria\" in dim_materia.columns else \"materia\"], \"id_materia\")\n",
    "hechos[\"id_espacio\"] = map_id(hechos, dim_espacio, \"codigo_salon\", \"codigo_salon\", \"id_espacio\")\n",
    "hechos = hechos.merge(dim_tiempo, on=[\"dia_codigo\",\"dia_semana\",\"h_inicio\",\"h_fin\"], how=\"left\")\n",
    "\n",
    "print(\"Filas sin id_materia:\", hechos[\"id_materia\"].isna().sum())\n",
    "\n",
    "hechos_horarios = hechos[[\n",
    "    \"id_docente\"    ,\"id_materia\",\"id_espacio\",\"id_tiempo\",\n",
    "    \"nrc\",\"clave\",\"secc\" if \"secc\" in hechos.columns else \"secci√≥n\" if \"secci√≥n\" in hechos.columns else \"d√≠as\",\n",
    "    \"duracion_min\"\n",
    "]].rename(columns=lambda c: {\"d√≠as\":\"seccion\"}.get(c, c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------------------------------------\\n# Guardar los resultados intermedios en archivos CSV\\n#-------------------------------------------------------------\\noutput_dir = Path(\"data_export\")\\noutput_dir.mkdir(exist_ok=True)\\n\\n#print(\">> Guardando archivos CSV intermedios en ./data_export/\")\\n\\nraw.to_csv(output_dir / \"data_raw.csv\", index=False, encoding=\"utf-8-sig\")\\ncurated.to_csv(output_dir / \"data_curated.csv\", index=False, encoding=\"utf-8-sig\")\\nhechos_clase.to_csv(output_dir / \"data_hechos.csv\", index=False, encoding=\"utf-8-sig\")\\ndim_docente.to_csv(output_dir / \"dim_docente.csv\", index=False, encoding=\"utf-8-sig\")\\ndim_materia.to_csv(output_dir / \"dim_materia.csv\", index=False, encoding=\"utf-8-sig\")\\ndim_espacio.to_csv(output_dir / \"dim_espacio.csv\", index=False, encoding=\"utf-8-sig\")\\ndim_tiempo.to_csv(output_dir / \"dim_tiempo.csv\", index=False, encoding=\"utf-8-sig\")\\n\\nprint(\">> Archivos CSV guardados correctamente en la carpeta \\'data_export\\'\")\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"-------------------------------------------------------------\n",
    "# Guardar los resultados intermedios en archivos CSV\n",
    "#-------------------------------------------------------------\n",
    "output_dir = Path(\"data_export\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#print(\">> Guardando archivos CSV intermedios en ./data_export/\")\n",
    "\n",
    "raw.to_csv(output_dir / \"data_raw.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "curated.to_csv(output_dir / \"data_curated.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "hechos_clase.to_csv(output_dir / \"data_hechos.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "dim_docente.to_csv(output_dir / \"dim_docente.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "dim_materia.to_csv(output_dir / \"dim_materia.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "dim_espacio.to_csv(output_dir / \"dim_espacio.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "dim_tiempo.to_csv(output_dir / \"dim_tiempo.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\">> Archivos CSV guardados correctamente en la carpeta 'data_export'\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Limpieza y validaci√≥n robusta de horas antes de la carga\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Normaliza tipos de hora\n",
    "raw[\"h_inicio\"] = pd.to_datetime(raw[\"h_inicio\"], errors=\"coerce\").dt.time\n",
    "raw[\"h_fin\"] = pd.to_datetime(raw[\"h_fin\"], errors=\"coerce\").dt.time\n",
    "\n",
    "# Quita filas sin hora v√°lida\n",
    "raw = raw.dropna(subset=[\"h_inicio\", \"h_fin\"]).reset_index(drop=True)\n",
    "\n",
    "# Filtra filas donde h_fin <= h_inicio\n",
    "def es_valida(row):\n",
    "    try:\n",
    "        return row[\"h_fin\"] > row[\"h_inicio\"]\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "mask_validas = raw.apply(es_valida, axis=1)\n",
    "raw = raw.loc[mask_validas].copy().reset_index(drop=True)\n",
    "\n",
    "# Recalcula duraci√≥n por consistencia\n",
    "def calcular_duracion(row):\n",
    "    try:\n",
    "        start = pd.to_datetime(str(row[\"h_inicio\"]), format=\"%H:%M:%S\")\n",
    "        end = pd.to_datetime(str(row[\"h_fin\"]), format=\"%H:%M:%S\")\n",
    "        dur = int((end - start).total_seconds() / 60)\n",
    "        return dur if dur > 0 else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "raw[\"duracion_min\"] = raw.apply(calcular_duracion, axis=1)\n",
    "raw = raw.dropna(subset=[\"duracion_min\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conexi√≥n a MySQL establecida correctamente.\n",
      ">> Creando tablas si no existen...\n",
      "‚úÖ Tablas creadas o verificadas correctamente.\n",
      "NaN limpiados en dim_docente\n",
      "NaN limpiados en dim_materia\n",
      "NaN limpiados en dim_espacio\n",
      "NaN limpiados en dim_tiempo\n",
      "NaN limpiados en hechos_clase\n",
      ">> Limpiando tablas existentes...\n",
      "‚úÖ Tablas limpiadas correctamente (Foreign Keys reactivadas).\n",
      "‚úÖ 105 filas insertadas en dim_docente\n",
      "‚úÖ 96 filas insertadas en dim_materia\n",
      "‚úÖ 42 filas insertadas en dim_espacio\n",
      "‚úÖ 47 filas insertadas en dim_tiempo\n",
      "Columnas en hechos_clase: ['id_docente', 'id_materia', 'id_espacio', 'id_tiempo', 'nrc', 'clave', 'seccion', 'duracion_min']\n",
      "‚úÖ 1184 filas insertadas en hechos_clase\n",
      "‚úÖ Todos los datos cargados exitosamente en MySQL.\n",
      "üîö Conexi√≥n a MySQL cerrada.\n"
     ]
    }
   ],
   "source": [
    "# pip install mysql-connector-python\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# CONFIGURACI√ìN GLOBAL\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"changocome\",  \n",
    "    \"host\": \"localhost\",\n",
    "    \"database\": \"horarios\",\n",
    "    \"allow_local_infile\": True\n",
    "}\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# CONEXI√ìN A MYSQL\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "try:\n",
    "    conn = mysql.connector.connect(**DB_CONFIG)\n",
    "    cursor = conn.cursor()\n",
    "    print(\"‚úÖ Conexi√≥n a MySQL establecida correctamente.\")\n",
    "except mysql.connector.Error as err:\n",
    "    if err.errno == errorcode.ER_ACCESS_DENIED_ERROR:\n",
    "        print(\"‚ùå Error: usuario o contrase√±a incorrectos.\")\n",
    "    elif err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(\"‚ùå Error: la base de datos no existe.\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error al conectar a MySQL: {err}\")\n",
    "    raise SystemExit()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# CREACI√ìN DE TABLAS (modelo estrella)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "ddl_statements = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_docente (\n",
    "        id_docente INT PRIMARY KEY,\n",
    "        nombre_completo VARCHAR(200)\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_materia (\n",
    "        id_materia INT PRIMARY KEY,\n",
    "        clave VARCHAR(50),\n",
    "        nombre_materia VARCHAR(200)\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_espacio (\n",
    "        id_espacio INT PRIMARY KEY,\n",
    "        edificio VARCHAR(50),\n",
    "        aula VARCHAR(50),\n",
    "        codigo_salon VARCHAR(100)\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS dim_tiempo (\n",
    "        id_tiempo INT PRIMARY KEY,\n",
    "        dia_codigo VARCHAR(10),\n",
    "        dia_semana VARCHAR(20),\n",
    "        hora_inicio TIME,\n",
    "        hora_fin TIME\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS hechos_horarios (\n",
    "        id_hecho INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        id_docente INT,\n",
    "        id_materia INT,\n",
    "        id_espacio INT,\n",
    "        id_tiempo INT,\n",
    "        nrc VARCHAR(20),\n",
    "        clave VARCHAR(50),\n",
    "        seccion VARCHAR(50),\n",
    "        duracion_min INT,\n",
    "        FOREIGN KEY (id_docente) REFERENCES dim_docente(id_docente),\n",
    "        FOREIGN KEY (id_materia) REFERENCES dim_materia(id_materia),\n",
    "        FOREIGN KEY (id_espacio) REFERENCES dim_espacio(id_espacio),\n",
    "        FOREIGN KEY (id_tiempo) REFERENCES dim_tiempo(id_tiempo)\n",
    "    )\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "print(\">> Creando tablas si no existen...\")\n",
    "for ddl in ddl_statements:\n",
    "    cursor.execute(ddl)\n",
    "conn.commit()\n",
    "print(\"Tablas creadas o verificadas correctamente.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Limpieza y normalizaci√≥n\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Renombrar columnas si existen\n",
    "if \"profesor\" in dim_docente.columns:\n",
    "    dim_docente.rename(columns={\"profesor\": \"nombreCompleto\"}, inplace=True)\n",
    "if \"materia\" in dim_materia.columns:\n",
    "    dim_materia.rename(columns={\"materia\": \"nombreMateria\"}, inplace=True)\n",
    "\n",
    "# Normalizar nombre de columna 'secc' -> 'seccion'\n",
    "if \"secc\" in hechos_horarios.columns:\n",
    "    hechos_horarios.rename(columns={\"secc\": \"seccion\"}, inplace=True)\n",
    "elif \"secci√≥n\" in hechos_horarios.columns:\n",
    "    hechos_horarios.rename(columns={\"secci√≥n\": \"seccion\"}, inplace=True)\n",
    "elif \"d√≠as\" in hechos_horarios.columns:\n",
    "    hechos_horarios.rename(columns={\"d√≠as\": \"seccion\"}, inplace=True)\n",
    "\n",
    "# Reemplazar NaN y valores \"nan\" o \"NaT\" por None\n",
    "def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.replace({np.nan: None, \"nan\": None, \"NaN\": None, \"NaT\": None})\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == object:\n",
    "            df[col] = df[col].astype(str).replace(\n",
    "                {\"nan\": None, \"None\": None, \"NaN\": None, \"NaT\": None, \"\": None}\n",
    "            )\n",
    "    return df\n",
    "\n",
    "for df_name, df in {\n",
    "    \"dim_docente\": dim_docente,\n",
    "    \"dim_materia\": dim_materia,\n",
    "    \"dim_espacio\": dim_espacio,\n",
    "    \"dim_tiempo\": dim_tiempo,\n",
    "    \"hechos_horarios\": hechos_horarios,\n",
    "}.items():\n",
    "    locals()[df_name] = clean_dataframe(df)\n",
    "    print(f\"NaN limpiados en {df_name}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Limpieza previa en base de datos\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "print(\">> Limpiando tablas existentes...\")\n",
    "cursor.execute(\"SET FOREIGN_KEY_CHECKS = 0;\")\n",
    "\n",
    "for table in [\"hechos_horarios\", \"dim_docente\", \"dim_materia\", \"dim_espacio\", \"dim_tiempo\"]:\n",
    "    cursor.execute(f\"TRUNCATE TABLE {table}\")\n",
    "\n",
    "cursor.execute(\"SET FOREIGN_KEY_CHECKS = 1;\")\n",
    "conn.commit()\n",
    "print(\"Tablas limpiadas correctamente (Foreign Keys reactivadas).\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helper: inserci√≥n segura de DataFrames\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def insert_dataframe(df: pd.DataFrame, table_name: str):\n",
    "    if df.empty:\n",
    "        print(f\"({table_name} est√° vac√≠o, no se inserta nada)\")\n",
    "        return\n",
    "    cols = \", \".join(df.columns)\n",
    "    placeholders = \", \".join([\"%s\"] * len(df.columns))\n",
    "    sql = f\"INSERT INTO {table_name} ({cols}) VALUES ({placeholders})\"\n",
    "    data = []\n",
    "    for row in df.itertuples(index=False, name=None):\n",
    "        clean_row = tuple(\n",
    "            None if (isinstance(x, float) and pd.isna(x)) or str(x).lower() in [\"nan\", \"nat\", \"none\", \"\"] else x\n",
    "            for x in row\n",
    "        )\n",
    "        data.append(clean_row)\n",
    "    cursor.executemany(sql, data)\n",
    "    conn.commit()\n",
    "    print(f\"{len(df)} filas insertadas en {table_name}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Inserci√≥n de datos (ajustada para mantener coherencia con el cubo)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# Convertir columnas de hora a formato HH:MM:SS\n",
    "for col in [\"h_inicio\", \"h_fin\"]:\n",
    "    if col in dim_tiempo.columns:\n",
    "        def to_mysql_time(x):\n",
    "            if pd.isna(x) or x in [None, \"\", \"None\", \"nan\", \"NaT\"]:\n",
    "                return None\n",
    "            # si es datetime.time\n",
    "            if hasattr(x, \"strftime\"):\n",
    "                return x.strftime(\"%H:%M:%S\")\n",
    "            # si es string, intenta parsear\n",
    "            try:\n",
    "                return pd.to_datetime(x, errors=\"coerce\").strftime(\"%H:%M:%S\")\n",
    "            except Exception:\n",
    "                return None\n",
    "        dim_tiempo[col] = dim_tiempo[col].apply(to_mysql_time)\n",
    "\n",
    "insert_dataframe(dim_docente, \"dim_docente\")\n",
    "insert_dataframe(dim_materia, \"dim_materia\")\n",
    "insert_dataframe(dim_espacio, \"dim_espacio\")\n",
    "insert_dataframe(dim_tiempo, \"dim_tiempo\")\n",
    "\n",
    "# Asegurar tipo entero antes de insertar\n",
    "if \"duracion_min\" in hechos_horarios.columns:\n",
    "    hechos_horarios[\"duracion_min\"] = hechos_horarios[\"duracion_min\"].astype(int)\n",
    "\n",
    "print(\"Columnas en hechos_horarios:\", hechos_horarios.columns.tolist())\n",
    "insert_dataframe(hechos_horarios, \"hechos_horarios\")\n",
    "\n",
    "print(\"Todos los datos cargados exitosamente en MySQL.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "#  Cierre\n",
    "# ---------------------------------------------------------------------------\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"Conexi√≥n a MySQL cerrada.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
